{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6949948,"sourceType":"datasetVersion","datasetId":3991463},{"sourceId":7753751,"sourceType":"datasetVersion","datasetId":4533733},{"sourceId":13599,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":11256}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:11:19.835052Z","iopub.execute_input":"2024-03-04T00:11:19.835321Z","iopub.status.idle":"2024-03-04T00:11:19.863806Z","shell.execute_reply.started":"2024-03-04T00:11:19.835296Z","shell.execute_reply":"2024-03-04T00:11:19.863064Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport math\nimport random\nimport numpy as np\nfrom tqdm import tqdm\nfrom scipy.stats import t as tdist\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name_or_path = \"gpt2-xl\"\ndataset_path = \"/kaggle/input/boolq-dev/dev.jsonl\"\ncontext_len = 256\npermutations_per_shard = 20\nmax_examples = 5000\n\nnum_shards = 50\ncontext_len = 256\nstride = 1024\ndevice = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:11:26.158296Z","iopub.execute_input":"2024-03-04T00:11:26.159147Z","iopub.status.idle":"2024-03-04T00:11:29.703304Z","shell.execute_reply.started":"2024-03-04T00:11:26.159115Z","shell.execute_reply":"2024-03-04T00:11:29.702424Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def load_dataset(dataset_path):\n    # For loading a JSON-serialized list of examples.\n    if dataset_path.endswith(\".json\"):\n        print(\"loading from json...\")\n        with open(dataset_path, \"r\") as f:\n            data = f.read()\n            examples = json.loads(data)\n            return examples\n\n    # For loading a dataset where each example is on its own line.\n    with open(dataset_path, \"r\") as f:\n        lines = f.readlines()\n    return lines","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:11:29.705212Z","iopub.execute_input":"2024-03-04T00:11:29.705810Z","iopub.status.idle":"2024-03-04T00:11:29.751552Z","shell.execute_reply.started":"2024-03-04T00:11:29.705771Z","shell.execute_reply":"2024-03-04T00:11:29.750625Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"examples = load_dataset(dataset_path)\nexamples = examples[:max_examples]\nnum_examples = len(examples)\nprint(f\"Loaded {num_examples} examples from {dataset_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:13:12.032631Z","iopub.execute_input":"2024-03-04T00:13:12.033568Z","iopub.status.idle":"2024-03-04T00:13:12.093331Z","shell.execute_reply.started":"2024-03-04T00:13:12.033536Z","shell.execute_reply":"2024-03-04T00:13:12.092044Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Loaded 3270 examples from /kaggle/input/boolq-dev/dev.jsonl\n","output_type":"stream"}]},{"cell_type":"code","source":"t = AutoTokenizer.from_pretrained(model_name_or_path)\ntokenized_examples = [t.encode(ex) for ex in examples]","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:13:14.185553Z","iopub.execute_input":"2024-03-04T00:13:14.185991Z","iopub.status.idle":"2024-03-04T00:13:16.037048Z","shell.execute_reply.started":"2024-03-04T00:13:14.185959Z","shell.execute_reply":"2024-03-04T00:13:16.036163Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_logprob_of_token_sequence(tokens, model, context_len=2048, stride=1024, device=0):\n    inputs = tokens[:-1]\n    targets = tokens[1:]\n\n    logp = torch.zeros((1, 1), dtype=torch.float32).to(device)\n\n    # compute the smallest multiple k of s so that t <= ks + c.\n    for j in range(math.ceil(max(0, len(inputs) - context_len) / stride)):\n        start = stride * j\n        end = min(stride * j + context_len, len(inputs))\n        rel_offs = max(0, context_len - stride) if j > 0 else 0\n\n        w_inp = inputs[start:end]\n        w_inp = torch.tensor(w_inp).to(device)\n        w_trg = targets[start:end]\n        w_trg = torch.tensor(w_trg).to(device)\n\n        model.eval()\n        with torch.no_grad():\n            out = model(torch.unsqueeze(w_inp, 0))\n            logps = torch.nn.functional.log_softmax(out.logits[0], dim=-1)\n            logps = logps.gather(-1, w_trg.unsqueeze(-1)).squeeze(-1)\n            logp += logps[rel_offs:].sum()\n\n        del w_inp\n        del w_trg\n        torch.cuda.empty_cache()\n\n    return logp.item()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:13:16.298784Z","iopub.execute_input":"2024-03-04T00:13:16.299577Z","iopub.status.idle":"2024-03-04T00:13:16.354430Z","shell.execute_reply.started":"2024-03-04T00:13:16.299543Z","shell.execute_reply":"2024-03-04T00:13:16.353419Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import gc\n\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:13:19.257802Z","iopub.execute_input":"2024-03-04T00:13:19.258523Z","iopub.status.idle":"2024-03-04T00:13:19.454539Z","shell.execute_reply.started":"2024-03-04T00:13:19.258483Z","shell.execute_reply":"2024-03-04T00:13:19.453294Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"shard_idx = enumerate([num_examples // num_shards] * num_shards)\nshard_counts = [(x + 1 if i < num_examples % num_shards else x) for i, x in shard_idx]\nshard_bounds = [0] + np.cumsum(np.asarray(shard_counts)).tolist()\n\nm = AutoModelForCausalLM.from_pretrained(model_name_or_path)\nm.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:13:19.685139Z","iopub.execute_input":"2024-03-04T00:13:19.685542Z","iopub.status.idle":"2024-03-04T00:13:25.581908Z","shell.execute_reply.started":"2024-03-04T00:13:19.685510Z","shell.execute_reply":"2024-03-04T00:13:25.580800Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 1600)\n    (wpe): Embedding(1024, 1600)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-47): 48 x GPT2Block(\n        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"flatten = lambda l : [x for s in l for x in s]\nshuffle = lambda l : random.sample(l, k=len(l))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:13:25.583868Z","iopub.execute_input":"2024-03-04T00:13:25.584330Z","iopub.status.idle":"2024-03-04T00:13:25.640734Z","shell.execute_reply.started":"2024-03-04T00:13:25.584283Z","shell.execute_reply":"2024-03-04T00:13:25.639779Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"canon, shuffled = [], []\n\nfor start, end in tqdm(list(zip(shard_bounds, shard_bounds[1:]))):\n    cur_tokens = flatten(tokenized_examples[start:end])\n    canon.append(compute_logprob_of_token_sequence(cur_tokens, m, context_len, stride, device))\n    shuffled.append([])\n    for _ in range(permutations_per_shard):\n        shuffled[-1].append(compute_logprob_of_token_sequence(shuffle(cur_tokens), m, context_len, stride, device))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:13:25.641936Z","iopub.execute_input":"2024-03-04T00:13:25.642241Z","iopub.status.idle":"2024-03-04T00:41:11.596648Z","shell.execute_reply.started":"2024-03-04T00:13:25.642208Z","shell.execute_reply":"2024-03-04T00:41:11.595493Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"100%|██████████| 50/50 [27:45<00:00, 33.32s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"def t_test(canon, shuffled):\n    diffs = canon - shuffled.mean(axis=1)\n    z = np.mean(diffs) / np.std(diffs) * np.sqrt(len(diffs))\n    pval = 1 - tdist.cdf(z, df=len(diffs)-1)\n    return pval","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:46:38.150181Z","iopub.execute_input":"2024-03-04T00:46:38.151175Z","iopub.status.idle":"2024-03-04T00:46:38.209988Z","shell.execute_reply.started":"2024-03-04T00:46:38.151110Z","shell.execute_reply":"2024-03-04T00:46:38.208942Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"canon = np.asarray(canon)\nshuffled = np.asarray(shuffled)\nt_test(canon, shuffled)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T00:46:38.806473Z","iopub.execute_input":"2024-03-04T00:46:38.806880Z","iopub.status.idle":"2024-03-04T00:46:38.867111Z","shell.execute_reply.started":"2024-03-04T00:46:38.806849Z","shell.execute_reply":"2024-03-04T00:46:38.865879Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"canon, shuffled = [], []\n\nfor start, end in tqdm(list(zip(shard_bounds, shard_bounds[1:]))):\n    cur_tokens = flatten(tokenized_examples[start:end])\n    canon.append(compute_logprob_of_token_sequence(cur_tokens, m, context_len, stride, device))\n    shuffled.append([])\n    for _ in range(permutations_per_shard):\n        shuffled[-1].append(compute_logprob_of_token_sequence(shuffle(cur_tokens), m, context_len, stride, device))","metadata":{},"execution_count":null,"outputs":[]}]}